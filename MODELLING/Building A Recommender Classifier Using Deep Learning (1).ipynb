{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Recommendation Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Let's start by loading the data as in the first lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.getcwd()\n",
    "os.chdir(r'C:\\Users\\MAIN\\Desktop\\ML\\Internship SMinds\\Recommender')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import dataset\n",
    "df = pd.read_csv(\"TripAdvReview.csv\", na_values=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Title  Rating  Review_counts  \\\n",
      "0                            Vacation/Cottage Rental     5.0           85.0   \n",
      "1    Mistiso's Place Vacation Rentals- Purcell Suite     4.5          100.0   \n",
      "2  Toronto 4 Bedroom House Spacious Clean Beautif...     5.0           36.0   \n",
      "3                                   Our Sweet Escape     5.0           34.0   \n",
      "4    Walk to ocean from Lyons Cottage Rentals in PEI     4.5           48.0   \n",
      "\n",
      "             City               Province  \\\n",
      "0   Niagara Falls                Ontario   \n",
      "1          Nelson       British Columbia   \n",
      "2         Toronto                Ontario   \n",
      "3  Qualicum Beach       British Columbia   \n",
      "4        Stanhope   Prince Edward Island   \n",
      "\n",
      "                                             Reviews  \n",
      "0  1 mention of vacation rentals\\nThis rental fel...  \n",
      "1  4 mentions of vacation rentals\\nI can't say en...  \n",
      "2  1 mention of vacation rentals\\nback yard! Woul...  \n",
      "3  3 mentions of vacation rentals\\nenjoyable. I h...  \n",
      "4  2 mentions of vacation rentals\\nquiet morning ...  \n"
     ]
    }
   ],
   "source": [
    "#remove extra columns and keep the necessary ones for analysis\n",
    "df = pd.DataFrame(df.drop(['Bubble_Count', 'Review_Count'], axis=1))\n",
    "df.columns\n",
    "print(df.head(n=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove new line characters from variable columns\n",
    "df = df.replace(r'\\n',' ', regex=True)\n",
    "\n",
    "#remove the numbers in the review column\n",
    "df.Reviews = df.Reviews.str.replace('\\d+', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fills the rating and Review_counts variable missing values with the mean and median respectively\n",
    "df = df.fillna({'Rating': df.Rating.median(), 'Review_counts': df.Review_counts.mean()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review_counts</th>\n",
       "      <th>City</th>\n",
       "      <th>Province</th>\n",
       "      <th>Reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Vacation/Cottage Rental</td>\n",
       "      <td>5.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>Niagara Falls</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>mention of vacation rentals This rental felt ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mistiso's Place Vacation Rentals- Purcell Suite</td>\n",
       "      <td>4.5</td>\n",
       "      <td>100.0</td>\n",
       "      <td>Nelson</td>\n",
       "      <td>British Columbia</td>\n",
       "      <td>mentions of vacation rentals I can't say enou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Toronto 4 Bedroom House Spacious Clean Beautif...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>mention of vacation rentals back yard! Would ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Our Sweet Escape</td>\n",
       "      <td>5.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>Qualicum Beach</td>\n",
       "      <td>British Columbia</td>\n",
       "      <td>mentions of vacation rentals enjoyable. I hav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Walk to ocean from Lyons Cottage Rentals in PEI</td>\n",
       "      <td>4.5</td>\n",
       "      <td>48.0</td>\n",
       "      <td>Stanhope</td>\n",
       "      <td>Prince Edward Island</td>\n",
       "      <td>mentions of vacation rentals quiet morning as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Best views in Nelson</td>\n",
       "      <td>5.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>Nelson</td>\n",
       "      <td>British Columbia</td>\n",
       "      <td>mentions of vacation rentals to buy even the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Shale Beach House, Blue Mountain Collingwood Ont.</td>\n",
       "      <td>5.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>Blue Mountains</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>mention of vacation rentals vacation spot! Th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Paradise Vacation Rentals</td>\n",
       "      <td>5.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>North Bay</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>This has to be one of the best vacation places...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Downtown Toronto 4BR Townhouse</td>\n",
       "      <td>5.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>mentions of vacation rentals paint but you co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Les Rives du Sanctuaire</td>\n",
       "      <td>5.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>Mont Tremblant</td>\n",
       "      <td>Quebec</td>\n",
       "      <td>mentions of vacation rentals spend majestic v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Inn Of The Sea Resort-Newly renovated, Oceanvi...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>Ladysmith</td>\n",
       "      <td>British Columbia</td>\n",
       "      <td>mentions of vacation rentals This is one of t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Enormous Riverfront 2 Bedroom Condo in the Hea...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>Quebec City</td>\n",
       "      <td>Quebec</td>\n",
       "      <td>mentions of vacation rentals Dalhousie, I can...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Downtown Apartment in Historic Cabbagetown</td>\n",
       "      <td>5.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>mentions of vacation rentals Tony and Steve's...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Air-con 3 BR view suite for 6, w/ 50' 4K Smart TV</td>\n",
       "      <td>5.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>Nanaimo</td>\n",
       "      <td>British Columbia</td>\n",
       "      <td>mentions of vacation rentals the windows beca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Downtown Toronto Furnished VACATION Rental</td>\n",
       "      <td>4.5</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>mention of vacation rentals rental! The locat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>By the Vines 3 Bedroom 2 Bath Wine Country Get...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>Niagara-on-the-Lake</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>mentions of vacation rentals recommend this h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>SURFS UP OCEANFRONT</td>\n",
       "      <td>5.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>Liverpool</td>\n",
       "      <td>Nova Scotia</td>\n",
       "      <td>mention of vacation rentals like a real home ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Tigh-na Clayoquot Vacation House Tofino BC</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Tofino</td>\n",
       "      <td>British Columbia</td>\n",
       "      <td>mention of vacation rentals order. It was a p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Howe Bay Beach House - PEI Oceanfront Vacation...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>Souris</td>\n",
       "      <td>Prince Edward Island</td>\n",
       "      <td>mention of vacation rentals rental enough. Wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Beach House on Square Bay</td>\n",
       "      <td>5.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Spring Bay</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>mention of vacation rentals Honestly the nice...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Lazy Dayz. Only 2 minutes from Picton Main Street</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Picton</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>mentions of vacation rentals very hospitable!...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Burgess Lookout Guest Cabin</td>\n",
       "      <td>5.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>Field</td>\n",
       "      <td>British Columbia</td>\n",
       "      <td>mentions of vacation rentals This is what oth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Simcoe Pines, 4 Bdrm Luxury home with heated pool</td>\n",
       "      <td>5.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>Niagara-on-the-Lake</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>mentions of vacation rentals Simcoe Pines pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>SHORE LARK BY THE SEA 1 BEDROOM VACATION RENTA...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>Petty Harbour</td>\n",
       "      <td>Newfoundland and Labrador</td>\n",
       "      <td>mention of vacation rentals Beautiful updated...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>The Hoblet,15 min. from the brink of Niagara F...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>Niagara Falls</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>mention of vacation rentals The Hoblet is a g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Stunning Secluded Oceanfront Island Home Near ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>Lunenburg</td>\n",
       "      <td>Nova Scotia</td>\n",
       "      <td>mention of vacation rentals I absolutely fell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Kitsilano's best, unique Coach House, license#...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>Vancouver</td>\n",
       "      <td>British Columbia</td>\n",
       "      <td>mention of vacation rentals to rent from. Thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Beautiful Home on Chesterman Beach</td>\n",
       "      <td>5.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>Tofino</td>\n",
       "      <td>British Columbia</td>\n",
       "      <td>mention of vacation rentals vacation! Could n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Kate's Cove</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Murray Harbour</td>\n",
       "      <td>Prince Edward Island</td>\n",
       "      <td>mentions of vacation rentals the twinkle of s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>69 Glaciers Reach this 2br home has a hot tub ...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>58.0</td>\n",
       "      <td>Whistler</td>\n",
       "      <td>British Columbia</td>\n",
       "      <td>mentions of vacation rentals Trevor and compa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Country In The City private 1 &amp; 2 Bedroom Suite</td>\n",
       "      <td>5.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>Niagara Falls</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>mention of vacation rentals The rental was a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Accommodation Vacation Rental West Shore Victoria</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Victoria</td>\n",
       "      <td>British Columbia</td>\n",
       "      <td>The bed was very comfortable and gave us a goo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Big Rock Vacation Rental - 203</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Campbell River</td>\n",
       "      <td>British Columbia</td>\n",
       "      <td>mentions of vacation rentals We stayed at the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Presidential Condo - 207 - SALE - HALF OFF CLE...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>27.0</td>\n",
       "      <td>Niagara Falls</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>mention of vacation rentals This Vacation Ren...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Mini Resort mins to beach and downtown Peachland</td>\n",
       "      <td>5.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>Peachland</td>\n",
       "      <td>British Columbia</td>\n",
       "      <td>mention of vacation rentals friendly and a gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Pat's Country Home</td>\n",
       "      <td>5.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>Niagara Falls</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>mention of vacation rentals lovely vacation t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Junior Presidential Condo - 110 - SALE - HALF ...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>25.0</td>\n",
       "      <td>Niagara Falls</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>mentions of vacation rentals vacation rentals...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Trenanthia Cottage (Hot Tub, Sauna, Games Room...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>74.0</td>\n",
       "      <td>Gravenhurst</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>cottage was great because unlike other rentals...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Far Horizons Luxury Vacation Home</td>\n",
       "      <td>5.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>Montebello</td>\n",
       "      <td>Quebec</td>\n",
       "      <td>mentions of vacation rentals Greg and Jen of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Luxury downtown condo, steps to Inner Harbor!!!</td>\n",
       "      <td>5.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>Victoria</td>\n",
       "      <td>British Columbia</td>\n",
       "      <td>mention of vacation rentals thought I would b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Cedar Ridge</td>\n",
       "      <td>4.5</td>\n",
       "      <td>18.0</td>\n",
       "      <td>Whistler</td>\n",
       "      <td>British Columbia</td>\n",
       "      <td>mentions of vacation rentals We stayed at Ced...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>The Crow's Nest Luxury Vacation Home In Trinit...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Trinity</td>\n",
       "      <td>Newfoundland and Labrador</td>\n",
       "      <td>equipped with every modern amenity you could h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>Manitoulin Island Cottage Rental</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>South Baymouth</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>We go every year to John Anita's house rental ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>Anglers Vacation Home</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Campbell River</td>\n",
       "      <td>British Columbia</td>\n",
       "      <td>mention of vacation rentals unreservedly reco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>Goose Cove Retreat</td>\n",
       "      <td>5.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>Trinity</td>\n",
       "      <td>Newfoundland and Labrador</td>\n",
       "      <td>mention of vacation rentals vacation homes in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>OCEANFRONT BEACH HOUSE - Black Rock Beach House</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>Ucluelet</td>\n",
       "      <td>British Columbia</td>\n",
       "      <td>mention of vacation rentals Black Rock Beach ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Bright, Cozy 1 bdrm apt. w/parking near Bluffs</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>mention of vacation rentals fantastic vacatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>***LAKEFRONT COTTAGE RENTAL ON LAKE ST. CLAIR***</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Lakeshore</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>Hello Stacy and Ken, It was a true delight to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>Blue Heron Cove c/w Algonquin Park Pass - 4yr ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>Algonquin Provincial Park</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>mention of vacation rentals company. This tru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>Bright Condo Close to Beach, Golf &amp; Royal Roads</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Victoria</td>\n",
       "      <td>British Columbia</td>\n",
       "      <td>mentions of vacation rentals If you ever need...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>grand-beach. ca Cabin Rental Manitoba grand beach</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>Grand Marais</td>\n",
       "      <td>Manitoba</td>\n",
       "      <td>recommend this cabin to anyone looking for a s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>La Belle Brise</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Cheticamp</td>\n",
       "      <td>Nova Scotia</td>\n",
       "      <td>mention of vacation rentals I'm glad I booked...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>Amberlea House; 5 bedroom w Heated Pool, Old Town</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Niagara-on-the-Lake</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>mention of vacation rentals when we are on va...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>28 Glaciers Reach, this 2br home has a hot tub...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>43.0</td>\n",
       "      <td>Whistler</td>\n",
       "      <td>British Columbia</td>\n",
       "      <td>mention of vacation rentals find the rental u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Surf Shack - Cozy Digs with Hot Tub - 2 Min wa...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>Tofino</td>\n",
       "      <td>British Columbia</td>\n",
       "      <td>mentions of vacation rentals make all the dif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Private Luxurious Penthouse suite. 2 Bedroom 2...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>Canmore</td>\n",
       "      <td>Alberta</td>\n",
       "      <td>mentions of vacation rentals were using. Neve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>300' lakefront, 50+ acres, Sat TV, Family Frie...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Spring Bay</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>mention of vacation rentals need for a family...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Absolutely Suite Vacation Rental</td>\n",
       "      <td>4.5</td>\n",
       "      <td>16.0</td>\n",
       "      <td>Oliver</td>\n",
       "      <td>British Columbia</td>\n",
       "      <td>We had a lovely time staying at Russell and Ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Avalon, English Country home with heated pool</td>\n",
       "      <td>5.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>Niagara-on-the-Lake</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>mention of vacation rentals We have had ten w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Red Bay Getaway</td>\n",
       "      <td>4.5</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Sauble Beach</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>mention of vacation rentals unwind. Thanks fo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Title  Rating  Review_counts  \\\n",
       "0                              Vacation/Cottage Rental     5.0           85.0   \n",
       "1      Mistiso's Place Vacation Rentals- Purcell Suite     4.5          100.0   \n",
       "2    Toronto 4 Bedroom House Spacious Clean Beautif...     5.0           36.0   \n",
       "3                                     Our Sweet Escape     5.0           34.0   \n",
       "4      Walk to ocean from Lyons Cottage Rentals in PEI     4.5           48.0   \n",
       "..                                                 ...     ...            ...   \n",
       "96   Private Luxurious Penthouse suite. 2 Bedroom 2...     5.0           32.0   \n",
       "97   300' lakefront, 50+ acres, Sat TV, Family Frie...     5.0           30.0   \n",
       "98                    Absolutely Suite Vacation Rental     4.5           16.0   \n",
       "99       Avalon, English Country home with heated pool     5.0           37.0   \n",
       "100                                    Red Bay Getaway     4.5           26.0   \n",
       "\n",
       "                    City               Province  \\\n",
       "0          Niagara Falls                Ontario   \n",
       "1                 Nelson       British Columbia   \n",
       "2                Toronto                Ontario   \n",
       "3         Qualicum Beach       British Columbia   \n",
       "4               Stanhope   Prince Edward Island   \n",
       "..                   ...                    ...   \n",
       "96               Canmore                Alberta   \n",
       "97            Spring Bay                Ontario   \n",
       "98                Oliver       British Columbia   \n",
       "99   Niagara-on-the-Lake                Ontario   \n",
       "100         Sauble Beach                Ontario   \n",
       "\n",
       "                                               Reviews  \n",
       "0     mention of vacation rentals This rental felt ...  \n",
       "1     mentions of vacation rentals I can't say enou...  \n",
       "2     mention of vacation rentals back yard! Would ...  \n",
       "3     mentions of vacation rentals enjoyable. I hav...  \n",
       "4     mentions of vacation rentals quiet morning as...  \n",
       "..                                                 ...  \n",
       "96    mentions of vacation rentals were using. Neve...  \n",
       "97    mention of vacation rentals need for a family...  \n",
       "98   We had a lovely time staying at Russell and Ch...  \n",
       "99    mention of vacation rentals We have had ten w...  \n",
       "100   mention of vacation rentals unwind. Thanks fo...  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop all missing values\n",
    "df.dropna(axis=0,how='any', inplace= True)\n",
    "df.head(n=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index=range(571)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(571, 6)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Title            0\n",
       "Rating           0\n",
       "Review_counts    0\n",
       "City             0\n",
       "Province         0\n",
       "Reviews          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type :  <class 'pandas.core.series.Series'>\n",
      "Length of reviews:  571\n",
      "Review at index 6:\n",
      "   mention of vacation rentals vacation spot! There are three levels and so each family got their very own\n",
      "Label of the review at Index 6:  5.0\n"
     ]
    }
   ],
   "source": [
    "# Let's understand the two lists: reviews (text_train) and their labels (y_train)\n",
    "print(\"Type : \",type(df.Reviews))\n",
    "print(\"Length of reviews: \",len(df.Reviews))\n",
    "print(\"Review at index 6:\\n \", df.Reviews[6])\n",
    "print(\"Label of the review at Index 6: \",df.Rating[6])\n",
    "# The ratings laels is a continous series of float numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter punctuations, stemming and stopwords\n",
    "corpus = []\n",
    "for i in range(len(df)):\n",
    "    review = re.sub('[^a-zA-Z0-9]', ' ', df['Reviews'][i])\n",
    "    review = review.lower()\n",
    "    tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "    stemmer = nltk.PorterStemmer()\n",
    "    lemmatizer = nltk.WordNetLemmatizer()\n",
    "    tokens_list = tokenizer.tokenize(review)\n",
    "    tokens = []\n",
    "    for token in tokens_list:\n",
    "        tokens.append(lemmatizer.lemmatize(token))\n",
    "        stop_words = stopwords.words(\"english\")\n",
    "    filtered_words = [w for w in tokens if w not in stop_words]\n",
    "    review = ' '.join(filtered_words)\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bag of Words model to convert corpus into X\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer()\n",
    "cv.fit(corpus)\n",
    "key = list(cv.vocabulary_.keys())\n",
    "key.sort()\n",
    "X = pd.DataFrame(cv.transform(corpus).toarray(),columns = key)\n",
    "y = df.Rating\n",
    "\n",
    "#TF_IDF model to convert corpus into X\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "X2 = pd.DataFrame(tfidf.fit_transform(corpus).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Label Encoding for Categorical Target Variable\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "lb = LabelEncoder()\n",
    "df['Rating'] = lb.fit_transform(df['Rating'])\n",
    "y=df.Rating\n",
    "Rating = df.Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6    372\n",
       "5    149\n",
       "4     31\n",
       "3      8\n",
       "2      5\n",
       "0      4\n",
       "1      2\n",
       "Name: Rating, dtype: int64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Rating.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <h4>We need to get unique words to determine the vocabulary size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = df.Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Unique words: 1856\n"
     ]
    }
   ],
   "source": [
    "uniq_words=set()\n",
    "for doc in reviews:\n",
    "    for word in doc.split(\" \"):\n",
    "        uniq_words.add(word)\n",
    "vocab_size=len(uniq_words)\n",
    "print (\"Total Unique words:\",vocab_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Time to import Keras and tensorflow modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>We need to convert each of the words in the reviews to one-hot vectors. Below is the code to get integer indexes of the words for one hot vector. Note that we don't need to store all zeros as only the integer index for the word in a vector will have a value of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1839, 154, 1210, 305, 861, 1354, 1688, 710, 1302, 1502, 1201, 384, 764, 1210, 462]\n"
     ]
    }
   ],
   "source": [
    "# Integer encode the documents\n",
    "\n",
    "encoded_reviews = [one_hot(review, vocab_size) for review in reviews]\n",
    "print(encoded_reviews[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>We also need to know in advance the length of the longest review. This information is needed to fix the size of the embedding matrix. We leave this as an exercise for you to determine the largest length of the review. We are curently fixing the maximum length to 100 words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1468  154 1210 ...    0    0    0]\n",
      " [1839  154 1210 ...    0    0    0]\n",
      " [1468  154 1210 ...    0    0    0]\n",
      " ...\n",
      " [1468  154 1210 ...    0    0    0]\n",
      " [1468  154 1210 ...    0    0    0]\n",
      " [ 307 1015 1301 ...    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "# pad documents to a max length of n words\n",
    "max_length = 50\n",
    "padded_reviews = pad_sequences(encoded_reviews, maxlen=max_length, padding='post')\n",
    "print(padded_reviews)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H4>We have completed our pre-processing, it is now time to build the neural network based classifier. But before we do that, let's split the reviews into training and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_rev=padded_reviews[0:1000]\n",
    "#train_lbls=Rating[0:1000]\n",
    "#test_rev=padded_reviews[1001:]\n",
    "#test_lbls=Rating[1001:]\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(padded_reviews,Rating,test_size=0.3, random_state=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Now we need to define the basics of model for neural network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_8 (Embedding)      (None, 50, 16)            29696     \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 3)                 2403      \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 2)                 8         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 32,110\n",
      "Trainable params: 32,110\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras import models\n",
    "# define the model\n",
    "model = Sequential()\n",
    "# Define the embedding matrix dimensions. Each vector is of 8 dimensions and there will be total of vocab_size vectors\n",
    "# The input length (window) is 100 words so the output from embedding layer will be a conactenated (flattened) vector of \n",
    "# 800 dimensions\n",
    "model.add(Embedding(vocab_size, 16, input_length=max_length))\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(units=3, activation='sigmoid'))\n",
    "model.add(Dense(units=2, activation='sigmoid'))\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "# compile the model with stochastic gradient descent and binary cross entropy\n",
    "model.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['acc'])\n",
    "# summarize the model\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "399/399 [==============================] - 0s 1ms/step - loss: -1.4507 - acc: 0.0000e+00\n",
      "Epoch 2/200\n",
      "399/399 [==============================] - 0s 63us/step - loss: -6.6763 - acc: 0.0025\n",
      "Epoch 3/200\n",
      "399/399 [==============================] - 0s 70us/step - loss: -12.2260 - acc: 0.0025\n",
      "Epoch 4/200\n",
      "399/399 [==============================] - 0s 70us/step - loss: -18.0758 - acc: 0.0025\n",
      "Epoch 5/200\n",
      "399/399 [==============================] - 0s 68us/step - loss: -23.7948 - acc: 0.0025\n",
      "Epoch 6/200\n",
      "399/399 [==============================] - 0s 63us/step - loss: -29.4822 - acc: 0.0025\n",
      "Epoch 7/200\n",
      "399/399 [==============================] - 0s 73us/step - loss: -35.1120 - acc: 0.0025\n",
      "Epoch 8/200\n",
      "399/399 [==============================] - 0s 90us/step - loss: -40.7576 - acc: 0.0025\n",
      "Epoch 9/200\n",
      "399/399 [==============================] - 0s 98us/step - loss: -46.4024 - acc: 0.0025\n",
      "Epoch 10/200\n",
      "399/399 [==============================] - 0s 73us/step - loss: -52.0693 - acc: 0.0025\n",
      "Epoch 11/200\n",
      "399/399 [==============================] - 0s 83us/step - loss: -57.7169 - acc: 0.0025\n",
      "Epoch 12/200\n",
      "399/399 [==============================] - 0s 95us/step - loss: -63.4472 - acc: 0.0025\n",
      "Epoch 13/200\n",
      "399/399 [==============================] - 0s 73us/step - loss: -69.2125 - acc: 0.0025\n",
      "Epoch 14/200\n",
      "399/399 [==============================] - 0s 80us/step - loss: -71.2723 - acc: 0.0025\n",
      "Epoch 15/200\n",
      "399/399 [==============================] - 0s 85us/step - loss: -71.3084 - acc: 0.0025\n",
      "Epoch 16/200\n",
      "399/399 [==============================] - 0s 68us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 17/200\n",
      "399/399 [==============================] - 0s 75us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 18/200\n",
      "399/399 [==============================] - 0s 78us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 19/200\n",
      "399/399 [==============================] - 0s 80us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 20/200\n",
      "399/399 [==============================] - 0s 80us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 21/200\n",
      "399/399 [==============================] - 0s 78us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 22/200\n",
      "399/399 [==============================] - 0s 78us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 23/200\n",
      "399/399 [==============================] - 0s 65us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 24/200\n",
      "399/399 [==============================] - 0s 63us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 25/200\n",
      "399/399 [==============================] - 0s 70us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 26/200\n",
      "399/399 [==============================] - 0s 73us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 27/200\n",
      "399/399 [==============================] - 0s 78us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 28/200\n",
      "399/399 [==============================] - 0s 65us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 29/200\n",
      "399/399 [==============================] - 0s 70us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 30/200\n",
      "399/399 [==============================] - 0s 65us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 31/200\n",
      "399/399 [==============================] - 0s 75us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 32/200\n",
      "399/399 [==============================] - 0s 75us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 33/200\n",
      "399/399 [==============================] - 0s 80us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 34/200\n",
      "399/399 [==============================] - 0s 78us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 35/200\n",
      "399/399 [==============================] - 0s 78us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 36/200\n",
      "399/399 [==============================] - 0s 70us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 37/200\n",
      "399/399 [==============================] - 0s 70us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 38/200\n",
      "399/399 [==============================] - 0s 70us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 39/200\n",
      "399/399 [==============================] - 0s 68us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 40/200\n",
      "399/399 [==============================] - 0s 60us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 41/200\n",
      "399/399 [==============================] - 0s 88us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 42/200\n",
      "399/399 [==============================] - 0s 95us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 43/200\n",
      "399/399 [==============================] - 0s 80us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 44/200\n",
      "399/399 [==============================] - 0s 75us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 45/200\n",
      "399/399 [==============================] - 0s 60us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 46/200\n",
      "399/399 [==============================] - 0s 63us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 47/200\n",
      "399/399 [==============================] - 0s 83us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 48/200\n",
      "399/399 [==============================] - 0s 85us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 49/200\n",
      "399/399 [==============================] - 0s 78us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 50/200\n",
      "399/399 [==============================] - 0s 75us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 51/200\n",
      "399/399 [==============================] - 0s 78us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 52/200\n",
      "399/399 [==============================] - 0s 65us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 53/200\n",
      "399/399 [==============================] - 0s 80us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 54/200\n",
      "399/399 [==============================] - 0s 75us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 55/200\n",
      "399/399 [==============================] - 0s 80us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 56/200\n",
      "399/399 [==============================] - 0s 65us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 57/200\n",
      "399/399 [==============================] - 0s 58us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 58/200\n",
      "399/399 [==============================] - 0s 68us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 59/200\n",
      "399/399 [==============================] - 0s 60us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 60/200\n",
      "399/399 [==============================] - 0s 63us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 61/200\n",
      "399/399 [==============================] - 0s 68us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 62/200\n",
      "399/399 [==============================] - 0s 60us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 63/200\n",
      "399/399 [==============================] - 0s 68us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 64/200\n",
      "399/399 [==============================] - 0s 65us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 65/200\n",
      "399/399 [==============================] - 0s 63us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 66/200\n",
      "399/399 [==============================] - 0s 73us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 67/200\n",
      "399/399 [==============================] - 0s 85us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 68/200\n",
      "399/399 [==============================] - 0s 73us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 69/200\n",
      "399/399 [==============================] - 0s 75us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 70/200\n",
      "399/399 [==============================] - 0s 73us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 71/200\n",
      "399/399 [==============================] - 0s 63us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 72/200\n",
      "399/399 [==============================] - 0s 65us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 73/200\n",
      "399/399 [==============================] - 0s 68us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 74/200\n",
      "399/399 [==============================] - 0s 60us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 75/200\n",
      "399/399 [==============================] - 0s 60us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 76/200\n",
      "399/399 [==============================] - 0s 70us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 77/200\n",
      "399/399 [==============================] - 0s 85us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 78/200\n",
      "399/399 [==============================] - 0s 93us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 79/200\n",
      "399/399 [==============================] - 0s 73us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 80/200\n",
      "399/399 [==============================] - 0s 75us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 81/200\n",
      "399/399 [==============================] - 0s 63us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 82/200\n",
      "399/399 [==============================] - 0s 58us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 83/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "399/399 [==============================] - 0s 73us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 84/200\n",
      "399/399 [==============================] - 0s 70us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 85/200\n",
      "399/399 [==============================] - 0s 60us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 86/200\n",
      "399/399 [==============================] - 0s 60us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 87/200\n",
      "399/399 [==============================] - 0s 55us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 88/200\n",
      "399/399 [==============================] - 0s 53us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 89/200\n",
      "399/399 [==============================] - 0s 63us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 90/200\n",
      "399/399 [==============================] - 0s 55us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 91/200\n",
      "399/399 [==============================] - 0s 53us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 92/200\n",
      "399/399 [==============================] - 0s 63us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 93/200\n",
      "399/399 [==============================] - 0s 68us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 94/200\n",
      "399/399 [==============================] - 0s 68us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 95/200\n",
      "399/399 [==============================] - 0s 65us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 96/200\n",
      "399/399 [==============================] - 0s 75us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 97/200\n",
      "399/399 [==============================] - 0s 78us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 98/200\n",
      "399/399 [==============================] - 0s 55us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 99/200\n",
      "399/399 [==============================] - 0s 58us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 100/200\n",
      "399/399 [==============================] - 0s 58us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 101/200\n",
      "399/399 [==============================] - 0s 55us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 102/200\n",
      "399/399 [==============================] - 0s 60us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 103/200\n",
      "399/399 [==============================] - 0s 53us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 104/200\n",
      "399/399 [==============================] - 0s 58us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 105/200\n",
      "399/399 [==============================] - 0s 83us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 106/200\n",
      "399/399 [==============================] - 0s 100us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 107/200\n",
      "399/399 [==============================] - 0s 103us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 108/200\n",
      "399/399 [==============================] - 0s 90us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 109/200\n",
      "399/399 [==============================] - 0s 83us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 110/200\n",
      "399/399 [==============================] - 0s 70us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 111/200\n",
      "399/399 [==============================] - 0s 80us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 112/200\n",
      "399/399 [==============================] - 0s 85us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 113/200\n",
      "399/399 [==============================] - 0s 80us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 114/200\n",
      "399/399 [==============================] - 0s 103us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 115/200\n",
      "399/399 [==============================] - 0s 100us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 116/200\n",
      "399/399 [==============================] - 0s 90us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 117/200\n",
      "399/399 [==============================] - 0s 90us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 118/200\n",
      "399/399 [==============================] - 0s 68us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 119/200\n",
      "399/399 [==============================] - 0s 68us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 120/200\n",
      "399/399 [==============================] - 0s 75us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 121/200\n",
      "399/399 [==============================] - 0s 65us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 122/200\n",
      "399/399 [==============================] - 0s 55us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 123/200\n",
      "399/399 [==============================] - 0s 58us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 124/200\n",
      "399/399 [==============================] - 0s 55us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 125/200\n",
      "399/399 [==============================] - 0s 58us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 126/200\n",
      "399/399 [==============================] - 0s 53us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 127/200\n",
      "399/399 [==============================] - 0s 68us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 128/200\n",
      "399/399 [==============================] - 0s 65us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 129/200\n",
      "399/399 [==============================] - 0s 65us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 130/200\n",
      "399/399 [==============================] - 0s 63us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 131/200\n",
      "399/399 [==============================] - 0s 70us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 132/200\n",
      "399/399 [==============================] - 0s 70us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 133/200\n",
      "399/399 [==============================] - 0s 58us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 134/200\n",
      "399/399 [==============================] - 0s 55us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 135/200\n",
      "399/399 [==============================] - 0s 58us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 136/200\n",
      "399/399 [==============================] - 0s 103us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 137/200\n",
      "399/399 [==============================] - 0s 55us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 138/200\n",
      "399/399 [==============================] - 0s 73us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 139/200\n",
      "399/399 [==============================] - 0s 60us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 140/200\n",
      "399/399 [==============================] - 0s 58us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 141/200\n",
      "399/399 [==============================] - 0s 58us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 142/200\n",
      "399/399 [==============================] - 0s 63us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 143/200\n",
      "399/399 [==============================] - 0s 85us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 144/200\n",
      "399/399 [==============================] - 0s 78us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 145/200\n",
      "399/399 [==============================] - 0s 70us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 146/200\n",
      "399/399 [==============================] - 0s 68us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 147/200\n",
      "399/399 [==============================] - 0s 60us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 148/200\n",
      "399/399 [==============================] - 0s 60us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 149/200\n",
      "399/399 [==============================] - 0s 63us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 150/200\n",
      "399/399 [==============================] - 0s 53us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 151/200\n",
      "399/399 [==============================] - 0s 68us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 152/200\n",
      "399/399 [==============================] - 0s 85us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 153/200\n",
      "399/399 [==============================] - 0s 80us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 154/200\n",
      "399/399 [==============================] - 0s 58us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 155/200\n",
      "399/399 [==============================] - 0s 58us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 156/200\n",
      "399/399 [==============================] - 0s 58us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 157/200\n",
      "399/399 [==============================] - 0s 58us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 158/200\n",
      "399/399 [==============================] - 0s 53us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 159/200\n",
      "399/399 [==============================] - 0s 60us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 160/200\n",
      "399/399 [==============================] - 0s 68us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 161/200\n",
      "399/399 [==============================] - 0s 60us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 162/200\n",
      "399/399 [==============================] - 0s 60us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 163/200\n",
      "399/399 [==============================] - 0s 55us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 164/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "399/399 [==============================] - 0s 60us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 165/200\n",
      "399/399 [==============================] - 0s 58us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 166/200\n",
      "399/399 [==============================] - 0s 55us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 167/200\n",
      "399/399 [==============================] - 0s 50us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 168/200\n",
      "399/399 [==============================] - 0s 53us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 169/200\n",
      "399/399 [==============================] - 0s 55us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 170/200\n",
      "399/399 [==============================] - 0s 55us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 171/200\n",
      "399/399 [==============================] - 0s 58us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 172/200\n",
      "399/399 [==============================] - 0s 53us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 173/200\n",
      "399/399 [==============================] - 0s 55us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 174/200\n",
      "399/399 [==============================] - 0s 55us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 175/200\n",
      "399/399 [==============================] - 0s 55us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 176/200\n",
      "399/399 [==============================] - 0s 58us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 177/200\n",
      "399/399 [==============================] - 0s 53us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 178/200\n",
      "399/399 [==============================] - 0s 53us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 179/200\n",
      "399/399 [==============================] - 0s 55us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 180/200\n",
      "399/399 [==============================] - 0s 53us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 181/200\n",
      "399/399 [==============================] - 0s 55us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 182/200\n",
      "399/399 [==============================] - 0s 55us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 183/200\n",
      "399/399 [==============================] - 0s 58us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 184/200\n",
      "399/399 [==============================] - 0s 55us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 185/200\n",
      "399/399 [==============================] - 0s 55us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 186/200\n",
      "399/399 [==============================] - 0s 60us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 187/200\n",
      "399/399 [==============================] - 0s 55us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 188/200\n",
      "399/399 [==============================] - 0s 55us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 189/200\n",
      "399/399 [==============================] - 0s 60us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 190/200\n",
      "399/399 [==============================] - 0s 55us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 191/200\n",
      "399/399 [==============================] - 0s 58us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 192/200\n",
      "399/399 [==============================] - 0s 55us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 193/200\n",
      "399/399 [==============================] - 0s 58us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 194/200\n",
      "399/399 [==============================] - 0s 55us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 195/200\n",
      "399/399 [==============================] - 0s 68us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 196/200\n",
      "399/399 [==============================] - 0s 83us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 197/200\n",
      "399/399 [==============================] - 0s 75us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 198/200\n",
      "399/399 [==============================] - 0s 60us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 199/200\n",
      "399/399 [==============================] - 0s 60us/step - loss: -71.3212 - acc: 0.0025\n",
      "Epoch 200/200\n",
      "399/399 [==============================] - 0s 55us/step - loss: -71.3212 - acc: 0.0025\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b16ad30438>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model... there are few docs, so I am trying with batch_size=1, you can delete it for default batch \n",
    "#size or change it to a bigger number\n",
    "model.fit(X_train, y_train, epochs=200,batch_size=30, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Now, we shall evaluate our model against the test set that we kep separate earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 813us/step\n",
      "Accuracy: 0.581395\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
    "print('Accuracy: %f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Bonus: Precision and Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 720us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.01      1.00      0.01         1\n",
      "           1       0.00      0.00      0.00         1\n",
      "           3       0.00      0.00      0.00         3\n",
      "           4       0.00      0.00      0.00         9\n",
      "           5       0.00      0.00      0.00        41\n",
      "           6       0.00      0.00      0.00       117\n",
      "\n",
      "   micro avg       0.01      0.01      0.01       172\n",
      "   macro avg       0.00      0.17      0.00       172\n",
      "weighted avg       0.00      0.01      0.00       172\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MAIN\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\MAIN\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\MAIN\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "predictions = model.predict(X_test, batch_size=100, verbose=1)\n",
    "predictions_bool = np.argmax(predictions, axis=1)\n",
    "\n",
    "print(classification_report(y_test, predictions_bool))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
